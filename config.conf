# Config File for MoCo

# Datset
--dataset= stl10          # Dataset   tinyimagenet
--dataset_path=None   #/home/duhan/MoCo-v2/data/tiny-imagenet-200/ #None   # Path to dataset, Not needed for TorchVision Datasets. /home/duhan/codes/dataset/ILSVRC2012/ /home/duhan/codes/MoCo-v2/data/tiny-imagenet-200/

# Model
--model=resnet18              # Model

# Epochs
--n_epochs=200                # Number of Epochs in Contrastive Training.   200
--finetune_epochs=100        # Number of Epochs in Linear Classification Training.  100
--warmup_epochs=10            # Number of Warmup Epochs During Contrastive Training.

# Core Training Params
--batch_size=256              # Number of Samples Per Batch. 128
--learning_rate=0.015        # Starting Learing Rate for Contrastive Training. 0.015 0.0075             0.015
--base_lr=0.03       # Base / Minimum Learing Rate to Begin Linear Warmup. 0.0001 0.03                0.03
--finetune_learning_rate=10.0 # Starting Learing Rate for Linear Classification 30.0

# Regularisation
--weight_decay=5e-4          # Contrastive Learning Weight Decay  1e-6 5e-4 1.5e-6                 5e-4
--finetune_weight_decay=0.0   # Linear Classification Training Weight Decay
--patience=100                # Number of Epochs to Wait for Improvement.

# Optimiser
--optimiser=sgd               # Optimiser sgd

# MoCo Options
--queue_size=65536           # Size of Memory Queue, Must be Divisible by batch_size.   65536 128
--queue_momentum=0.99         # Momentum for the Key Encoder Update. 0.99 0.9
--temperature=0.07           # InfoNCE Temperature Factor 0.07 0.5

# Augmentation
--jitter_d=0.5                # Distortion Factor for the Random Colour Jitter
--jitter_p=0.8                # Probability to Apply Random Colour Jitter
--blur_sigma=[0.1,2.0]        # Radius to Apply Random Colour Jitter
--blur_p=0.5                  # Probability to Apply Gaussian Blur
--grey_p=0.2                  # Probability to Apply Random Grey Scale
; --no_twocrop                  # Whether or Not to Use Two Crop Augmentation


# Distirbuted Options
--no_distributed=False              # Whether or Not to Use Distributed Training
# --nnodes=1
# --node_rank=0
# --nproc_per_node=2


# Finetune Options
; --finetune                    # Perform Only Linear Classification Training
; --supervised                  # Perform Supervised Pre-Training
; --load_checkpoint_dir=<PATH>  # Path to Load Pre-trained Model
